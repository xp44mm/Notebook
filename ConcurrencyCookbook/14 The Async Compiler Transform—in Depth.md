CHAPTER 14 The Async Compiler Transform—in Depth

Async is implemented in the C# compiler with some help from the .NET framework base class libraries. The runtime itself didn’t need any changes to support async. That means await is implemented by a transformation to something that we could have written ourselves in earlier versions of C#. We can use a decompiler like .NET Reflector to take a look at the generated code.

As well as being interesting, understanding the generated code is helpful for debugging, performance analysis, and other diagnostics on async code.

The stub Method

The async method is replaced by a stub method. The first thing that happens when you call an async method is that the stub method runs. Let’s look at this simple async method as an example:

```C#
public async Task<int> AlexsMethod()
{
    int foo = 3;
    await Task.Delay(500);
    return foo;
}
```

The stub method generated by the compiler looks like this:

```C#
public Task<int> AlexsMethod()
{
    <AlexsMethod>d__0 stateMachine = new <AlexsMethod>d__0();
    stateMachine.<>4__this = this;
    stateMachine.<>t__builder = AsyncTaskMethodBuilder<int>.Create();
    stateMachine.<>1__state = -1;
    stateMachine.<>t__builder.Start<<AlexsMethod>d__0>(ref stateMachine);
    return stateMachine.<>t__builder.Task;
}
```

I’ve manually improved the names of the variables to make it easier to understand. As we saw in “Async, Method Signatures, and Interfaces” on page 22, the async key-word has no effect on how the method is used from the outside. That becomes obvious when you see that the signature of the stub method is always just the same as the original async method, but without the async keyword.

You’ll notice that none of my original code is in the stub method. Most of the stub method consists of initializing the variables of a struct, called <AlexsMethod>d__0. That struct is a state machine and is where all the hard work is done. The stub method calls a method Start, then it returns a Task. To understand what is happening, we need to look inside the state machine struct itself.

The State Machine Struct

The compiler generates a struct that acts as a state machine and contains all the code of my original method. It does this so that there is an object capable of representing the state of the method, which can be stored when execution reaches an await. Remember that when we reach an await, everything about where we are in the method is remem-bered, so it can be restored when the method is resumed.

Although it would be feasible for the compiler to go through and store each local vari-able of your method when it pauses, it would be a lot of generated code. A better way is to change all the local variables of your method into member variables of a type, so we can just store the instance of the type and all the local variables will automatically be kept as well. That’s exactly what this struct is for.

The state machine is a struct rather than a class for performance reasons. It means that when an async method completes synchronously, it doesn’t need to be allocated to the heap. Unfortunately, being a struct makes it harder for us to reason about.

The state machine is generated as an inner struct of the type containing the async method. That makes it easy to work out which method it was generated from, but is primarily so it can access the private members of your type.

Let’s look at the state machine struct <AlexsMethod>d__0 generated for our example.

For now, we’ll concentrate on the member variables:

```C#
public int <>1__state;
public int <foo>5__1;
public AlexsClass <>4__this;
public AsyncTaskMethodBuilder<int> <>t__builder;
private object <>t__stack;
private TaskAwaiter <>u__$awaiter2;
```

All the variables have angle brackets in their names. That’s just to mark them as compiler generated. It is important in other compiler generated code, which has to coexist with user code because angle brackets can’t be used in variables in valid C#. Here, it’s not really necessary.

First, the state variable, <>1__state, is a place to store the await we have reached. Before we reach any await, its value is -1. Each await in the original method is numbered, and when the method is paused, the number of the await to resume from is written to the state variable.

Next is <foo>5__1, which stores the value of my original variable foo. We’ll see soon that all accesses to my foo have been replaced by accesses to this member variable instead.

Then, we have <>4__this. This only appears in the state machine for non-static async methods and contains the object that the async method was part of. In a way, you can think of this as just another local variable in a method, which happens to be used implicitly when you access other members of the same object. After the async trans-formation, it needs to be stored and used explicitly, because my code has been moved from its original object to the state machine struct.

The AsyncTaskMethodBuilder is a helper type that contains the logic that all of these state machines share. This is what creates the Task that is returned by the stub method. In fact, its job is very similar to TaskCompletionSource, in that it creates a puppet Task to return, which it can complete later. The difference from TaskCompletionSource is that it is optimized for async methods, and uses tricks like being a struct rather than a class for performance.

Async methods that return void use AsyncVoidMethodBuilder as their helper, while async methods that return Task<T> use a generic version, AsyncTaskMethodBuilder<T>.

The stack variable, <>t__stack, is used for awaits which are part of a larger expres-sion. .NET intermediate language (IL) is a stack-based language, so complex expressions are built of small instructions which manipulate a stack of values. When the await is in the middle of that kind of complex expression, the current values in the stack are placed in this stack variable, inside a Tuple if there is more than one.

Finally, the TaskAwaiter variable is temporary storage for the object that helps the await keyword to sign up for notification when the Task completes.

The MoveNext Method

The state machine always has a method called MoveNext, where all your original code ends up. This method is called both when the method is first run and when we resume from an await. Even for the simplest async method, it is overwhelmingly complex to look at, so I’ll try to explain the transformation as a series of steps. I’ll also skip over some less relevant details, so this description is not completely accurate in a lot of places.

The method was called MoveNext originally because of its similarity to the MoveNext methods generated by iterator blocks in earlier versions of C#. Those implement IEnumerable in a single method using the yield return keyword. The state machine system used there is similar to the async state machine, although simpler.

Your Code

The first step is to copy your code into the MoveNext method. Remember that any accesses to variables need to change to point at the new member variable of the state machine instead. Where the await was, I’ll leave a gap which we’ll need to fill later.

```C#
<foo>5__1 = 3;
Task t = Task.Delay(500);
Logic to await t goes here
return <foo>5__1;
```

Transforming Returns to Completions

Every return statement in the original code needs to be converted to code that will
complete the Task that was returned by the stub method. In fact, MoveNext returns
void, so our return foo; isn’t even valid.

```C#
<>t__builder.SetResult(<foo>5__1);
return;
```


Of course, after completing the Task, we use return; to exit from MoveNext.

Get to the Right Place in the Method

Because MoveNext is called to resume from each await, as well as when the method is first started, we need to start by jumping to the right place in the method. This is done using IL similar to that generated by a switch statement, as if we are switching on the state.

```C#
switch (<>1__state)
{
    case -1: // Right at the start of the method
        <foo>5__1 = 3;
        Task t = Task.Delay(500);
        Logic to await t goes here
    case 0: // There's only one await, so it is number 0
        <>t__builder.SetResult(<foo>5__1);
        return;
}
```

Pausing the Method for the await

This is where we use the TaskAwaiter to sign up for notification of when the Task we’re
awaiting completes. We need to update the state to make sure we resume at the right
point. Once everything is signed up and ready, we return, releasing the thread to do
other things as a good asynchronous method must.

```C#
...
    <foo>5__1 = 3;
    <>u__$awaiter2 = Task.Delay(500).GetAwaiter();
    <>1__state = 0;
    <>t__builder.AwaitUnsafeOnCompleted(<>u__$awaiter2, this);
    return;
case 0:
...
```

The AsyncTaskMethodBuilder is also involved in signing up for notification, and the process is complicated. This is where advanced features of await are organized, like capturing a SynchronizationContext to use to resume. But the end result is easy to understand. When the Task completes, our MoveNext method will be called again.

Resuming after the Await

Once the Task we were awaiting completes, and we’re back at the right point of the MoveNext method, we still need to get the result of the Task before proceeding with my code. In this example, we are using a non-generic Task, so there’s no value to read into a variable. But there’s still the chance that the Task is faulted, and an exception needs to be thrown. Calling GetResult on the TaskAwaiter does all this.

```C#
...
case 0:
    <>u__$awaiter2.GetResult();
    <>t__builder.SetResult(<foo>5__1);
...
```

Completing Synchronously

Remember that when await is used on a Task that already completed synchronously, execution should proceed without having to pause and resume the method. To achieve that, we need to check whether the Task is completed before returning. If it is, we just use goto case to jump to the right place to continue.

```C#
...
<>u__$awaiter2 = Task.Delay(500).GetAwaiter();
if (<>u__$awaiter2.IsCompleted)
{
    goto case 0;
}
<>1__state = 0;
...
```

The great thing about compiler-generated code is that no one has to maintain it, so you can use goto as much as you like. I had previously never heard of goto case statements, and that’s probably a good thing.

Catching Exceptions

If an exception is thrown during the execution of your async method, and there’s no try..catch block to handle it, the compiler-generated code will catch it instead. It does this so it can set the returned Task to faulted, rather than letting the exception escape. Remember that the MoveNext method can be called from either the original caller of the async method, or by an awaited Task that has completed, possibly via a Synchroniza tionContext. None of these are expecting an exception to escape.

```C#
try
{
    ... Whole method
}
catch (Exception e)
{
    <>t__builder.SetException(<>t__ex);
    return;
}
```

More Complicated Code

My example was very simple. The MoveNext method becomes much more complicated if you introduce features like:

• try..catch..finally blocks

• Branches (if and switch)

• Loops

• Using await in the middle of an expression

The compiler transform does handle all of these constructs correctly, so as the pro-grammer, you don’t need to worry about how complex they would be.

I would encourage you to use a decompiler to look at a MoveNext method for one of your own async methods. Try to spot the simplifications I’ve made in this description, and work out how more complex code is transformed.

Writing Custom Awaitable Types

Task is an awaitable type, in that you can apply await to it. As we saw in “IAsyncAction and IAsyncOperation<T>” on page 74, other types can also be awaitable, for example the WinRT type IAsyncAction. In fact, although you should never need to, it’s possible to write your own awaitable types.

To be awaitable, the type needs to provide the abilities used by the MoveNext method that we just saw. First, it needs to have a method called GetAwaiter:

```C#
class MyAwaitableClass
{
    public AlexsAwaiter GetAwaiter()
    {
        ...
```

That GetAwaiter method can be an extension method, which is a really important flex-
ibility. For example, IAsyncAction doesn’t have a GetAwaiter method, because it is from
WinRT, and WinRT has no concept of awaitable types. IAsyncAction becomes await-
able because an extension method GetAwaiter is provided by .NET.

Then, the type returned by GetAwaiter has to follow a specific pattern in order that
MyAwaitableClass is considered awaitable. The minimum required is:

• It implements INotifyCompletion, so it contains a method void OnCompleted(Action
handler), which signs up for notification of completion

• It contains a property bool IsCompleted { get; }, which is used to check for
synchronous completion

• It contains a method T GetResult(), which returns the result of the operation, and
throws any exceptions

The return type T of GetResult can be void, like it is for Task. Alternatively, it can be a
real type, like it is for Task<T>. Only in the second case will the compiler let you use the
await as an expression—for example, by assigning the result to a variable.

Here’s what AlexsAwaiter might look like:

```C#
class AlexsAwaiter : INotifyCompletion
{
    public bool IsCompleted
    {
        get
        {
            ...
        } 
    }
    public void OnCompleted(Action continuation)
    {
        ... 
    }
    public void GetResult()
    {
        ...
    }
}
```


It’s important to remember that TaskCompletionSource exists, and that it’s usually a much better option when you need to turn something asynchronous into something awaitable. Task has a lot of useful features and you don’t want to miss out on them.

Interacting with the Debugger

You might think that after the compiler has moved your code around so much, the Visual Studio debugger would have trouble making sense of it to show you what’s happening. In fact, the debugging experience is very good. This is primarily achieved by the compiler linking the lines in your source code with the parts of the MoveNext method that were converted from your code. This mapping, stored in the .pdb file, means that these features of the debugger work normally:

• Setting breakpoints

• Stepping between lines that don’t include an await

• Viewing the correct line where an exception was thrown

However, if you look closely while stopped at a breakpoint after an await in an async method, you can see that the compiler transform has taken place. The clues are:

• The name of the current method will appear to be MoveNext in some places. The Call Stack window translates it back to the original method name successfully, but Intellitrace doesn’t.

• The Call Stack window shows that the call stack contains frames from the TPL infrastructure, followed by [Resuming Async Method], followed by your method.

The real magic is stepping through the code. In a heroic effort, the Visual Studio debugger can correctly Step Over (F10) an await, despite the method continuing an indeterminate time in the future on an indeterminate thread. You can see the infra-structure that went into this ability in AsyncTaskMethodBuilder, which has a property called ObjectIdForDebugger. The debugger can also Step Out (Shift+F11) from an async method, which will take you to just after the await, which is currently waiting for it to complete.

CHAPTER 15 The Performance of Async Code

When you choose to use async code, you’re probably thinking about performance.

Whether that’s the responsiveness of a UI application, the throughput of a server, or
enabling parallelism using actors, you need to know that the change is actually going
to be worthwhile.

To think about the performance of async code, you have to look at it in comparison to
the alternatives that are relevant in each situation. In this chapter, we will consider:

• Situations with a long-running operation that has the potential to be executed
asynchronously

• Situations  with  no  long-running  operation,  where  there’s  no  opportunity  to
execute asynchronously

• Comparisons  of  async  code  against  standard  code,  which  blocks  during  long-
running operations

• Comparisons of async code against manual asynchronous code
We’ll also discuss a few optimizations that can be useful if you find that the extra
overhead of the async machinery is causing a performance problem in your application.

Measuring Async Overhead

The machinery of async methods inevitably uses more processor cycles than the equiv-
alent  synchronous  code,  and  the  switches  between  threads  add  extra  latency.  It’s
impossible to measure the performance overhead of an async method exactly. The
performance in your application depends on what other threads are doing, cache be-
havior, and other unpredictable factors. There’s also a distinction between processor
usage and added latency, since an asynchronous system can easily add time to an
operation without using the CPU, while a request is waiting in a queue to be executed.

So I’ll just give you an order of magnitude analysis to the nearest factor of 10. I’ll use
the cost of a normal method call as a baseline for comparisons. My laptop can call a
method roughly 100 million times per second.

Async Versus Blocking for a Long-Running Operation

The usual reason to use async code is a long-running operation that you can execute
asynchronously, freeing up resources. In UI code, unless that operation is sure to be
quick, it’s usually worth using async to keep the UI responsive. In server-side code, the
trade-off is much more subtle, as you are trading the extra memory footprint of blocked
threads for the extra processor overhead of the async methods.

The overhead of an async method which actually executes asynchronously depends
entirely on whether it needs to switch threads using SynchronizationContext.Post. If it
does, the overhead is dominated by the thread switch it performs as it resumes. That
means that the current SynchronizationContext makes a big difference. I’ve measured
this overhead by running this method, which does nothing but await Task.Yield, which
always completes asynchronously:

```C#
async Task AlexsMethod()
{
    await Task.Yield();
}
```


Table 15-1. Overhead to execute and resume an async method

Whether we need to pay to switch threads depends on the SynchronizationContext of the original caller, as well as the SynchronizationContext of the thread which completed our Task.

• If they are the same, there’s no need to Post to the original Synchronization Context, and the method can be resumed by the thread that completed the Task, synchronously, as part of completing the Task.

• If the original caller had a SynchronizationContext, but not the same one as the completion thread, we need to do the Post, incurring the high cost shown in the table. This also happens if the completion thread has no SynchronizationContext.

• If the original caller had no SynchronizationContext—for example, in a console application, then what happens depends on the SynchronizationContext of the completion thread. If there is a SynchronizationContext, .NET assumes that the thread is important and schedules our method to resume on the thread pool. If the completion thread has no SynchronizationContext, or just the default thread pool one, it resumes our method on the same thread, synchronously.

In reality, the .NET thread pool is so fast that the overhead of switching to it doesn’t even show up in my order of magnitude numbers, when compared to resuming the method in the same thread. Given that, you don’t really need to worry about the SynchronizationContext of the completion thread.

These rules mean that a chain of async methods will tend to incur one expensive thread switch, as the deepest method resumes. After that, the SynchronizationContexts will be the same, and the rest of the methods can resume cheaply. The thread switch in a UI context is one of the most expensive. However, in a UI application, the user’s ex-perience is so bad if you don’t use async code that you don’t have a real choice. If you are doing a network request that takes 500ms, it’s worth paying another millisecond for a responsive UI.

Unfortunately, WPF recreates SynchronizationContext objects often, so in a WPF context, a deep stack of async methods incurs the large cost of a WPF Post for every method resumed. Windows forms and Win-dows 8 applications don’t suffer from the same problem.

The trade-off requires more thought in server-side code—for example, ASP.NET applications. Whether async code is worthwhile depends largely on whether your server has a bottleneck in memory usage, because the biggest cost of using many threads is memory. Many factors can cause your synchronous application to consume memory faster than it consumes processor time, including:

• You call long-running operations that take a relatively long time

• You parallelize long-running operations by using extra threads

• Many requests call through to the long-running operations, rather than being served by in-memory caches

• Generating the response doesn’t require very much processor time

The only way to really know is to measure the memory usage of your server. If the memory usage is a problem, and the memory is being used by too many threads, async is a good solution. It uses a little more CPU, but when the server is running out of memory and has plenty of CPU, that’s no problem.

Remember that while async methods will always use more processor time than syn-chronous methods, the difference is really quite small, and can easily be dominated by anything else your application does.

Optimizing Async Code for a Long-Running Operation

If your async code runs truly asynchronously, as we’ve seen, the largest overhead is the Post call to the calling SynchronizationContext, which causes a thread switch. As we discussed in “Choosing Not to Use SynchronizationContext” on page 51, you can use ConfigureAwait to opt out of that Post, to avoid paying the cost of the thread switch until it’s really necessary. If your code is called in the WPF UI thread, it can be useful to avoid the repeated Posts.

The other context of the calling thread, captured by the ExecutionContext class, is also a source of overhead when writing async methods. As we saw in the section “Con-text” on page 27, .NET will capture and restore the ExecutionContext at every await.

If you don’t use ExecutionContext, the process of capturing and restoring the default context is heavily optimized, and very cheap. If you use any of the contexts captured by ExecutionContext, it becomes much more expensive. So, avoid using CallContext, LogicalCallContext, or impersonation in async code to improve performance.

Async Versus Manual Asynchronous Code

If you have existing UI code, it probably avoids responsiveness problems by some form of manual asynchronous technique. There are a variety of possible approaches, including:

• Creating a new thread

• Using ThreadPool.QueueUserWorkItem to do the long-running work on a back-ground thread

• Using a BackgroundWorker

• Consuming an asynchronous API manually

All approaches involve at least one transfer back to the UI thread to present the result to the user, in the same way that async does automatically. In some of these approaches, this is implicit (for example, the RunWorkerCompleted event of BackgroundWorker), while in some, you need to explicitly call a BeginInvoke method.

The difference in speed between these approaches is relatively small, apart from cre-ating a new thread, which is much slower. Async is at least as fast as any of them, if you avoid ExecutionContext. In fact, I find it a few percent faster than any other approach.

Because it’s slightly faster, and because the code is more readable, I would always use async in preference to any of these techniques.

Async Versus Blocking Without a Long-Running Operation

A very common situation is to write a method that can take a long time occasionally, but is very fast 99% of the time. One example is a network request with a cache, where most requests can be served from the cache. The choice of whether to use async code for this kind of operation could be dependent on the overhead in the common case when the code completes synchronously rather than the overhead in the 1% of cases where it actually uses the asynchronous network operation.

Remember that the await keyword won’t actually pause the method when it doesn’t need to, in case it is given a Task that is already complete. The method containing that await can then also finish synchronously, in turn returning a Task that is already com-plete. In that way, entire chains of async methods can run synchronously.

Async methods, even when they run synchronously, are inevitably slower than their non-async equivalents. And now, there’s no advantage to be gained through resources being released. The so-called async method isn’t asynchronous, and the so-called blocking method doesn’t block. However, the advantages of being asynchronous in the 1% of cases that the cache can’t serve the request could be so large that it’s worth writing async code anyway.

It all depends on how much slower async code is than non-async code, when they both return synchronously from a cache.

Again, this is really hard to measure accurately, because it depends so much on the situation. I find that calling an empty async method is 10 times slower than calling an empty non-async method.

It sounds slower than the non-async code, but remember, this is just the overhead. It will almost always be dominated by the actual work you’re doing. For example, a lookup in a Dictionary<string, string> also costs around the same as 10 empty method calls.

Optimizing Async Code Without a Long-Running Operation

The overhead of an async method that completes synchronously, about 10 times the cost of an empty non-async method, comes from a few different places. Most of it is inevitable—for example, running the compiler-generated code, making its calls to the framework, and losing optimizations that are impossible because of the exception han-dling behavior of async methods.

The largest avoidable part of the overhead is the allocation of objects on the heap. It is very cheap to actually allocate an object. However, allocating more objects means the garbage collector needs to run more often, and it is expensive for an object to still be in use during a garbage collection.

The async machinery is designed to allocate as few objects as possible. That’s why the state machine is a struct, as are the AsyncTaskMethodBuilder types. They are only moved to the heap if the async method is paused.

Task is not a struct, however, so it always needs to be allocated on the heap. For this reason, .NET has a few preallocated Tasks that are used when an async method com-pletes synchronously, and returns one of a few common values, for example:

• A non-generic, successfully completed Task

• A Task<bool> containing true or false

• A Task<int> containing a small number

• A Task<T> containing null

If you are writing a cache that needs to have very high performance, and none of these apply, you can avoid the allocation by caching the completed Task rather than the value.

It’s rarely worthwhile, though, as you are likely to be allocating objects elsewhere in the code anyway.

So, in conclusion, async methods that finish synchronously are already very fast, and optimizing them further is hard. Only consider spending effort on caching Tasks if your application isn’t as fast as you’d like, and you find that garbage collection is the issue.

Async Performance Summary

While async code always uses more processor time than the equivalent synchronous code, the difference is usually small in comparison to the operation that you’re making asynchronous. In server-side code, the cost needs to be weighed against the memory footprint of the extra threads. In UI code, and when using actors for parallelism, async code is both faster and neater than implementing asynchronous patterns manually, so we should always use it.

Finally, when an operation usually completes immediately, there is no harm in using async code, because it is only slightly slower than the equivalent non-async code.
